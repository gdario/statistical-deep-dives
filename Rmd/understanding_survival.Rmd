---
title: "Understanding the `survival` Package"
author: "Giovanni d'Ario"
date: "2025-04-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The survival package is extremely powerful, but also rather complex, and not very intuitive. The documentation is also not easy to navigate. It contains classes and methods that do a lot of stuff, and it's sometimes difficult to understand what a method is doing, or what a component of an object corresponds to.

```{r}
library(survival)
dset <- read.csv("../data/Practical_Rott_dev.csv", header = TRUE) |>
  dplyr::mutate(
    size = factor(size),
    grade = factor(grade)
  )

dplyr::glimpse(dset)
```
## Basic Non-Parametric Estimators

### Creating a survival object with `Surv()`

The function `Surv()` creates a survival object. In this document we will only consider right-censoring.

### Fitting survival curves with `survfit()`

The generic function `survfit()` creates survival curves from either a formula (`survfit.formula`), as is the case below, or from a fitted Cox model (`survfit.coxph`), covered in the next section. It can also take an accelerated failure time model, but we will not cover this case here.

The object produced by the `survfit()` generic function is a `survfit` object which has class `survfit`. To see the documentation associated with this object, one cannot type `help(survfit)` as this would show the documentation for the generic function, but rather `help(survfit.object)`. The documentation of `survfit.formula` says that the function

> Computes an estimate of a survival curve for censored data using the Aalen-Johansen estimator. For ordinary (single event) survival this reduces to the Kaplan-Meier estimate.

In terms of output, the documentation expains that

> The routine returns both an estimated probability in state and an estimated cumulative hazard estimate. For simple survival the probability in state = probability alive, i.e, the estimated survival.

If we look at the components of a `survfit` object, we have

```{r}
sdata <- Surv(dset$rfsurv / 12, dset$rfsi) 
km_fit <- survfit(sdata ~ 1)
names(km_fit)
```

We see that the `survfit` object contains:

- `n`: the total number of observations.
- `time`: the unique time points.
- `n.risk`: the number of individuals at risk at each time point.
- `n.event`: the number of events at each time point.
- `n.censor`: the number of censored individuals at each time point.
- `surv`: a vector of $n_t$ elements, where $n_t$ is the number of unique time-points, i.e., the length of the `$time` component. Note that $t_0 = 0$ is not included in `$time` and `$surv`. Between $t_0$ and $t_1$ the survival function has value 1.
- `cumhaz`: Vector similar to `$surv`, but containing the values of the cumulative hazard function

There are several additional elements, including those that allow plotting the confidence intervals of the survival and of the cumulative hazard functions, respectively. The `km_fit` object, therefore, contains all the element necessary to estimate the survival function, the cumulative hazard function, the corresponding standard errors, and a few more pieces of information.

The code snippet below shows the methods associated with the `survfit` object. Note the `median()` and the `quantile()` functions.

```{r}
class(km_fit)
methods(class = class(km_fit))
```

Typically we are primarily interested in the `median`, `plot`, `print`, `summary` methods.

```{r}
median(km_fit)
quantile(km_fit, c(0.25, 0.50, 0.75), conf.int = FALSE)
```

Looking at the help page for `plot.survfit()` we see that there is a `cumhaz` argument, which is `FALSE` by default. Let's see how this changes what is plotted by the plot method.

```{r}
plot(km_fit)
```

```{r}
plot(km_fit, cumhaz = TRUE)
```

Setting `cumhaz = TRUE` plots the cumulative hazard instead of the survival function.

The `print.survfit()` method has two useful arguments: `scale` and `rmean`. The first, `scale` allows to print time in units different than the original ones. For example, we defined `sdata` such that time is expressed in years. Let's print the results in weeks (52 weeks in an year). If time was expressed in days and we wanted it expressed in years, we should write `scale = 365`. In our case we must *divide* by 52.

```{r}
print(km_fit)
print(km_fit, scale = 1/52)
```

The other useful argument is `rmean`. This computes the Restricted Mean Survival Time (RMST), which is an estimate of the expected survival time within a given time window. In the example below we print the RMST at 2 and 5 years.

```{r}
print(km_fit, rmean = 2)
print(km_fit, rmean = 5)
```

The `summary.survfit()` function

> Returns a list containing the survival curve, confidence limits for the curve, and other information.

In the "Details" section, we can read that

> This routine has two uses: printing out a survival curve at specified time points (often yearly), or extracting the values at specified time points for further processing.

The output of `summary(km_fit)` is very long, and we don't print it here. By default, the output is a list with the following components:

```{r}
names(summary(km_fit))
```

There is, however, a `data.frame` argument set to `FALSE` by default which, when set to `TRUE`, returns a data frame with columns `time`, `n.risk`, `n.event`, `n.censor`, `surv`, `cumhaz`, `strata`, `data`, and the columns associated with the standard error, if `se.fit = TRUE`.

```{r}
names(summary(km_fit, data.frame = TRUE))
```

Note that you can pass `summary.survfit()` a vector of `times` to obtain information only about those timepoints. In the example below we print, among other things, the survival probability at 2 and 5 years.

```{r}
summary(km_fit, times = c(2, 5))
```

We can extract the components of the summary for the time points of interest.

```{r}
summary(km_fit, times = c(2, 5))$surv
summary(km_fit, times = c(2, 5))$cumhaz
```

If we want to extract several components, e.g., survival and/or cumulative hazard and their standard error, we can use the `data.frame=TRUE` argument.

```{r}
summary(km_fit, data.frame = TRUE, times = c(2, 5))
```

Note that

> When the ‘times’ argument contains values not in the data, the routine can only use a best guess for the number at risk, i.e., the number at risk at the next event/censoring time.

### Estimating the hazard function

There seems to be no method to compute the hazard function associated with a `survfit` object. The Kaplan-Meier estimate of the hazard function is

$$
\hat h(t) = \frac{d_j}{n_j \tau_j}
$$

where $\tau_j = t_(j+1) - t(j)$. We can write a small function that computes this K-M estimator.

```{r}
km_hazard <- function(x) {
  res <- data.frame(
    t1 = c(0, x$time),
    n = c(x$n, x$n.risk),
    d = c(0, x$n.event),
    c = c(0, x$n.censor)
  )
  res <- res[res$c == 0, ]
  res$t2 <- c(res$t1[-1], max(x$time))
  res$tau <- res$t2 - res$t1
  res$haz <- res$d / (res$n * res$tau)
  res
}

plot_km_hazard <- function(x) {
  tmp <- km_hazard(x)
  plot(tmp$t1 , tmp$haz, type = "s", xlab = "Time", ylab = "Hazard")
}
```

We consider the small dataset from example 1.1 in Collett's book, to verify that we obtain the same results and the same plot.

```{r}
ex1.1 <- data.frame(
  time = c(10, 13, 18, 19, 23, 30, 36, 38, 54, 56, 59, 75,
            93, 97, 104, 107, 107, 107),
  status = c(1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0)
)
tmp <- survfit(Surv(ex1.1$time, ex1.1$status) ~ 1)
```

```{r}
km_hazard(tmp)
```

```{r}
plot_km_hazard(tmp)
```

These are the same table and the same plot in Collett's book, which makes us confident that the function is not too far from being correct.

When applied to our dataset, the "manual" version of the hazard function looks very wiggly, with extreme peaks and an unrealistic amount of variability.

```{r}
plot_km_hazard(km_fit)
```

The `muhaz` package provides a smooth estimate of the hazard function for censored data. There are several choices for the smoothing parameters. The plot below uses the default settings. Note the different range of the y-axis in the two plots.

```{r}
plot(muhaz::muhaz(dset$rfsurv / 12, dset$rfsi))
```

## Cox Proportional Hazards Method

We will now fit a Cox proportional hazard model to this dataset. For simplicity, we will consider only two predictors, `age` and `nodes`. We will make no effort to optimize this model, which is used only for illustration purposes. The `print.coxph()` method provides a concise summary of the fit.

```{r}
fit <- coxph(sdata ~ age + nodes, data = dset)
print(fit)
```

The output, `fit`, is an object of class `coxph`. Like for `survfit`, the documentation for this object is under `coxph.object`. According to the documentation, this object has methods `print`, `summary`, `residuals`, and `survfit`.

```{r}
names(fit)
```

There are several elements of interest. `fit$coefficients` just provides the estimates, without the standard errors. `fit$loglik` contains two values:

```{r}
fit$loglik
```

According to the documentation `fit$loglik` is

> a vector of length 2 containing the log-likelihood with the initial values and with the final values of the coefficients.

The initial values are set to zero by default, as explained in the documentation for `coxph()`, and specifically for the `init` argument.

If we take the difference of the first value and the second, and multiply by negative two, we get exactly the value of the likelihood ratio test.

```{r}
-2 * (fit$loglik[1] - fit$loglik[2])
```

Rather strangely, there seems to be no slot in the `survfit.object` containing the value of the likelihood ratio test.

To gain an insight of how the likelihood ratio test is computed, we can look at the source code of `survival:::print.coxph()`. The snippet below is extracted from it, and we can see that both the test value and the associated p-value are computed on the fly, and not stored in a component of the output list.

```{r, eval=FALSE}
logtest <- -2 * (x$loglik[1] - x$loglik[2])
# some more code
cat("Likelihood ratio test=", format(round(logtest, 2)), 
    "  on ", df, " df,", " p=", format.pval(pchisq(logtest, 
            df, lower.tail = FALSE), digits = digits), "\n", 
    sep = "")
```

The values of `fit$wald.test` and `fit$score` are also based on the comparison of the initial and final values.

The `summary()` function contains some information related to these tests. One can, for example, compare the following

```{r}
fit$wald.test
summary(fit)$waldtest
```

The latter returns information on the degrees of freedom and the p-value. Similar results for the score test

```{r}
fit$score
summary(fit)$sctest
```

information about `Concordance` is more abundant in the `coxph.object` than in its summary

```{r}
fit$concordance
summary(fit)$concordance
```

The `fit$concordance` component is a vector of 6 elements containing

1. The number of concordant pairs.
2. The number of discordant pairs.
3. The number of pairs tied on x.
4. The number of pairs tied on y.
5. The number of pairs tied on both.
6. The concordance statistic.

```{r}
fit$concordance
```

The `fit$linear.predictors` component contains the vector of *centered* linear predictors. Let's compare the values below:

```{r}
fit$linear.predictors[1:10]
```

with those obtained from manually extracting the linear predictor:

```{r}
(model.matrix(fit) %*% fit$coefficients)[1:10]
```

These values are quite different. Let's see what happens if we center the model.matrix.

```{r}
(scale(model.matrix(fit), center = TRUE, scale = FALSE) %*% fit$coefficients)[1:10]
```

We obtain exactly the content of `fit$linear.predictor`.

## Making Predictions

Objects of class `coxph.object` have a `predict` method. According to the documentation, `predict.coxph()` 

> Compute fitted values and regression terms for a model fitted by `coxph`

moreover the documentation explains that

> The Cox model is a relative risk model; predictions of type "linear predictor", "risk", and "terms" are all relative to the sample from which they came. By default, the reference value for each of these is the mean covariate within strata.

The `predict.coxph` method takes a `coxph` object and, optionally, a `newdata` data frame. The `type` argument specifies the type of predicted value. Possible choices are:

1. `lp`: the linear predictor.
2. `risk`: the risk score, which is equal to `exp(lp)`.
3. `expected`: the expected number of events given the covariates and follow-up time.
4. `terms`: the terms of the linear predictor. **TODO** clarify.
5. `survival`: the survival probability, which can also be obtained as `exp(-expected)`.

Let's take a closer look at some of these.

### `lp`

If we set `type = "lp"` we obtain once again the *centered* linear predictors.

```{r}
predict(fit, type = "lp")[1:10]
```

### `risk`

As we said, these should correspond to `exp(lp)`, where `lp` is the linear predictor.

```{r}
all.equal(
  predict(fit, type = "risk"),
  exp(predict(fit, type = "lp"))
)
```

This is just $e^{\eta_i}$ where $\eta_i$ is the linear predictor for the i-th patient. Since

$$\frac{h(x_i, t)}{h_0(t)} = e^{\eta_i}$$ 

this quantity gives the constant hazard ratio w.r.t. the baseline hazard $h_0(t)$ for the i-th patient. More in general, every patient with the same set of predictors as the i-th patient will have the same risk.

### `expected` and `survival`

These two differ from the previous ones. In fact, according to the documentation:

> Predictions of type "expected" or "survival" incorporate the baseline hazard and are thus absolute instead of relative

We can verify that the two quantities are indeed easily obtained from each other.

```{r}
all.equal(
  predict(fit, type = "survival"),
  exp(-predict(fit, type = "expected"))
)
```

## Predictions with `survfit.coxph`

According to the documentation, `survfit.coxph`

> Computes the predicted survivor function for a Cox proportional hazards model.

### Do we need to compute the baseline hazard?

It is important to note that, if we want to estimate the survival probability for a given set of predictors at a given set of time points, we don't need to explicitly compute the baseline hazard. The output depends on whether we pass a `newdata` argument or not. According to the documentation

> If the newdata argument is missing, then a curve is produced for a single "pseudo" subject with covariate values equal to the means component of the fit. The resulting curve(s) rarely make scientific sense, but the default remains due to an unwarranted belief by many that it represents an "average" curve, and it's use as a default in other packages.

The plot below shows the survival curve for the "pseudo" subject.

```{r}
sfit <- survfit(fit)
plot(sfit, xlab = "Time (years)", ylab = "Survival probability")
```

Therefore the real power of `survfit.coxph` comes from passing a data frame to the `newdata` argument. If we do so, we obtain a survival curve *for each row* of the data frame. For example:

```{r}
sfit <- survfit(fit, newdata = data.frame(age = c(23, 54), nodes = c(0, 5)))
names(sfit)
plot(sfit, col = c("green", "red"),
     xlab = "Time (years)",
     ylab = "Survival probability")
```

### Estimating survival at given time points

This object allows to extract the estimated survival probability for any individual at any time via the `summary.survfit()` method. As noted above for formulas, the times of interest can be specified via the `times` argument.

```{r}
summary(sfit[1], times = c(5, 10))
```

And, as was the case for formulas, we can have a richer output as a data frame.

```{r}
summary(sfit, times = c(5, 10), data.frame = TRUE)
```

